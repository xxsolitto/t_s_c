{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdb5fe80-e688-4eef-a240-c1c8a6495fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tweepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a11b20155208>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtwarc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTwarc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpansions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tweepy'"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "from twarc import Twarc2, expansions\n",
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "from nltk.stem.porter import PorterStemmer as PS\n",
    "import time\n",
    "import schedule\n",
    "import datetime\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0032ec5a-1d71-4faf-a1cb-696b3c235730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization\n",
    "import stanza\n",
    "stanza.download('en') # download English model\n",
    "nlp = stanza.Pipeline('en') # initialize English neural pipeline\n",
    "doc = nlp(\"Barack Obama was born in Hawaii.\") # run annotation over a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b605f0-dedf-465b-bb24-dd62b23c5c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma')\n",
    "doc = nlp('Her bags are better than his.')\n",
    "print(*[f'word: {word.text+\" \"}\\tlemma: {word.lemma}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b7cdde-f8e0-4b2e-b55c-b2000edb8890",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma')\n",
    "\n",
    "def lemma(txt):\n",
    "    s = ''\n",
    "    doc = nlp(txt)\n",
    "    \n",
    "    for sent in doc.sentences:\n",
    "        for word in sent.words:\n",
    "            s += word.lemma + ' '\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8334a9-8ef1-4f9e-b997-b322b8b64479",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./tweet-sentiment/2021-01_slist.csv',usecols = ['Compound'])\n",
    "df2 = pd.read_csv('./tweet-sentiment/2021-01_slist_Number0.csv', usecols = ['Compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc41d8a5-2fba-4fd1-987b-cd0fdf37cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"bool\"] = (df1['Compound'] == df2['Compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143c071e-1a06-4b96-b0f3-7f5d72177e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = df1.compare(df2)\n",
    "df_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581b9f0e-01ad-49ac-8d1a-fc4fbd711fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del df3\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6691812-e3f9-44ce-b58d-24f7f485bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./binance/BTCUSDT/1d/BTCUSDT-1d-2021-01.csv',usecols = [,'open','close'])\n",
    "df.head(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106c9a64-b1b5-4836-8917-174ea868555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.pct_change()\n",
    "print(df1['open'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb3e83d-5433-4d3b-abe5-efe4683575cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831279b9-963e-4b18-87e2-96d63f5b3b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.diff())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546a1292-f74c-4403-a51a-aa0a6f7ac3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=1612051200000\n",
    "b=1611964800000\n",
    "print((a-b)/24,(a-b)/(24*3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6ae520-9d65-48e5-afd6-f820f79660b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print (pd.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0801ba66-e0cf-49d2-ba43-8870401df9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('binance/BTCUSDT/15m/BTCUSDT-15m-2021-01.zip') as existing_zip:\n",
    "    existing_zip.extractall('binance/BTCUSDT/15m')\n",
    "with zipfile.ZipFile('binance/BTCUSDT/15m/BTCUSDT-15m-2021-02.zip') as existing_zip:\n",
    "    existing_zip.extractall('binance/BTCUSDT/15m')\n",
    "with zipfile.ZipFile('binance/BTCUSDT/15m/BTCUSDT-15m-2021-03.zip') as existing_zip:\n",
    "    existing_zip.extractall('binance/BTCUSDT/15m')\n",
    "with zipfile.ZipFile('binance/BTCUSDT/15m/BTCUSDT-15m-2021-04.zip') as existing_zip:\n",
    "    existing_zip.extractall('binance/BTCUSDT/15m')\n",
    "with zipfile.ZipFile('binance/BTCUSDT/15m/BTCUSDT-15m-2021-05.zip') as existing_zip:\n",
    "    existing_zip.extractall('binance/BTCUSDT/15m')\n",
    "with zipfile.ZipFile('binance/BTCUSDT/15m/BTCUSDT-15m-2021-06.zip') as existing_zip:\n",
    "    existing_zip.extractall('binance/BTCUSDT/15m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87acf1e9-8144-461f-8687-d647f8ad13b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    17497\n",
      "2    17338\n",
      "1    17293\n",
      "Name: trend, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "timespan = '5m'\n",
    "files = [f'tweet-sentiment/{timespan}/2021-01.csv',\n",
    "             f'tweet-sentiment/{timespan}/2021-02.csv',\n",
    "             f'tweet-sentiment/{timespan}/2021-03.csv',\n",
    "             f'tweet-sentiment/{timespan}/2021-04.csv',\n",
    "             f'tweet-sentiment/{timespan}/2021-05.csv',\n",
    "             f'tweet-sentiment/{timespan}/2021-06.csv']\n",
    "datas = []\n",
    "df = pd.DataFrame()\n",
    "for file in files:\n",
    "    data = pd.read_csv(file)\n",
    "    datas.append(data)\n",
    "\n",
    "df = pd.concat(datas).reset_index(drop=True)\n",
    "\n",
    "print(df['trend'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "624cd652-bce4-4871-8456-22d37e4a9c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2ee5054-a4e8-42a7-92ec-1668c3868370",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'tweet-sentiment/1d/2021-01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4dd048d-32e6-40d7-856b-f523b48a2d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "['neg_count(n)' 'neu_count(n)' 'pos_count(n)' 'open_price(n)' 'trend(n)'\n",
      " 'trend(n+1)' 'open_price(n+1)' 'neg_count(n-1)' 'neu_count(n-1)'\n",
      " 'pos_count(n-1)' 'trend(n-1)']\n"
     ]
    }
   ],
   "source": [
    "n=2\n",
    "timespan=str(\"1d\")\n",
    "\n",
    "files = [f'tweet-sentiment/{timespan}/2021-01.csv',\n",
    "         f'tweet-sentiment/{timespan}/2021-02.csv',\n",
    "         f'tweet-sentiment/{timespan}/2021-03.csv',\n",
    "         f'tweet-sentiment/{timespan}/2021-04.csv',\n",
    "         f'tweet-sentiment/{timespan}/2021-05.csv',\n",
    "         f'tweet-sentiment/{timespan}/2021-06.csv']\n",
    "datas = []\n",
    "df = pd.DataFrame()\n",
    "for file in files:\n",
    "    data = pd.read_csv(file, usecols = ['section','neg_count','neu_count','pos_count','open_price','trend'])\n",
    "    datas.append(data)\n",
    "\n",
    "# ファイルの結合\n",
    "df = pd.concat(datas).reset_index(drop=True)\n",
    "df = df.drop(columns=['section'])\n",
    "\n",
    "# カラム名変更(区間No.割り当て)\n",
    "df = df.rename(columns={\"neg_count\":\"neg_count(n)\", \n",
    "                        \"neu_count\":\"neu_count(n)\", \n",
    "                        \"pos_count\":\"pos_count(n)\", \n",
    "                        \"open_price\":\"open_price(n)\",\n",
    "                        \"trend\":\"trend(n)\"})\n",
    "\n",
    "# 目的変数\n",
    "df['trend(n+1)'] = df['trend(n)'].shift(-1)\n",
    "\n",
    "# 説明変数\n",
    "df['open_price(n+1)'] = df['open_price(n)'].shift(-1)\n",
    "if n >= 2:\n",
    "    for i in range(1,n):\n",
    "        df[f'neg_count(n-{i})'] = df['neg_count(n)'].shift(i)\n",
    "        df[f'neu_count(n-{i})'] = df['neu_count(n)'].shift(i)\n",
    "        df[f'pos_count(n-{i})'] = df['pos_count(n)'].shift(i)\n",
    "        df[f'trend(n-{i})'] = df['trend(n)'].shift(i)\n",
    "        if i==n-1: break\n",
    "        df[f'open_price(n-{i})'] = df['open_price(n)'].shift(i)\n",
    "else:\n",
    "    df = df.drop(columns=['open_price(n)'])\n",
    "\n",
    "        \n",
    "print(len(df.columns.values))\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62e98eb7-88a9-4414-9126-a22eecc31dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg_count(n)         int64\n",
      "neu_count(n)         int64\n",
      "pos_count(n)         int64\n",
      "open_price(n)      float64\n",
      "trend(n)             int64\n",
      "trend(n+1)         float64\n",
      "open_price(n+1)    float64\n",
      "neg_count(n-1)     float64\n",
      "neu_count(n-1)     float64\n",
      "pos_count(n-1)     float64\n",
      "trend(n-1)         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94b736af-ec50-474d-9aa9-3c3ed1fa40ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log リセット\n",
    "df = pd.DataFrame(columns=['start_time',\n",
    "                   'end_time',\n",
    "                   'timespan',\n",
    "                   'kind_of_data',\n",
    "                   'range_of_data',\n",
    "                   'attribute',\n",
    "                   'all_data',\n",
    "                   'training_data',\n",
    "                   'test_data',\n",
    "                   'accuracy',\n",
    "                   'confusion_matrix',\n",
    "                   'score_report'])\n",
    "df.to_csv('tweet-svm/svm_log.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "435af25f-8166-464c-818d-aee7694649de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweet-svm/svm_log.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5a1a010-e0fb-4db5-8ceb-016522ca8fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.5714285714285714, 'recall': 0.47058823529411764, 'f1-score': 0.5161290322580646, 'support': 17}\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "df = pd.read_csv('tweet-svm/svm_log.csv')\n",
    "\n",
    "str = \"{'名前':'太郎', '身長':'165', '体重':'60'}\"\n",
    "dic = ast.literal_eval(df['score_report'][8])\n",
    "print(dic['0.0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccca7402-6a8b-4ab3-aaa0-2b9880543c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習に用いる感情データの種類 a\n",
      "1 : neg_count, neu_count, pos_count + end_price, trend\n",
      "2 : com_ave, tweet_cont + end_price, trend\n",
      "3 : all + end_price, trend\n",
      "4 : neg_count, neu_count, pos_count\n",
      "5 : com_ave, tweet_cont\n",
      "6 : all\n",
      "7 : end_price, trend\n"
     ]
    }
   ],
   "source": [
    "s = ('学習に用いる感情データの種類 a\\n' \n",
    "     '1 : neg_count, neu_count, pos_count + end_price, trend\\n'\n",
    "     '2 : com_ave, tweet_cont + end_price, trend\\n'\n",
    "     '3 : all + end_price, trend\\n'\n",
    "     '4 : neg_count, neu_count, pos_count\\n'\n",
    "     '5 : com_ave, tweet_cont\\n'\n",
    "     '6 : all\\n'\n",
    "     '7 : end_price, trend')\n",
    "print(s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "917ba47e-cb34-460f-9952-f758c3d0653a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================timespan='5m'==============================\n"
     ]
    }
   ],
   "source": [
    "timespan='5m'\n",
    "print('='*30 + f'{timespan=}' + '='*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba7fd68-435d-4f23-b391-4e444ca2de5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
