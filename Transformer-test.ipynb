{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "425ceb85-d9ff-409a-880f-1d0f94c562c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext.legacy import data\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "import torch.nn.utils.rnn as rnn\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49ed922d-7105-492e-861f-e3d842113ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "„Éá„Éº„ÇøË™≠„ÅøËæº„ÅøÂÆå‰∫Ü\n",
      "ËæûÊõ∏‰ΩúÊàêÂÆå‰∫Ü\n",
      "„É°„É¢„É™Ëß£Êîæ\n"
     ]
    }
   ],
   "source": [
    "# „Éá„Éº„Çø„ÅÆÂâçÂá¶ÁêÜÔºàWord EmbeddingÔºâ\n",
    "# Ë©¶‰ΩúVer\n",
    "\n",
    "# „ÉÜ„Ç≠„Çπ„Éà„ÇíÂçòË™û„ÅßÂàÜÂâ≤\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# data fieldÂÆöÁæ©\n",
    "TEXT_N  = data.Field(sequential=True, lower=True, tokenize=tokenizer, init_token='<cls>')\n",
    "#SECTION = data.Field(sequential=False, use_vocab=False)\n",
    "#TREND_N = data.Field(sequential=False, use_vocab=False)\n",
    "#PRICE_N = data.Field(sequential=False, use_vocab=False)\n",
    "LABEL = data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "\n",
    "# CSV„Éï„Ç°„Ç§„É´„ÇíË™≠„ÅøËæº„Åø„ÄÅTabularDataset„Ç™„Éñ„Ç∏„Çß„ÇØ„Éà„ÅÆ‰ΩúÊàê\n",
    "train_data, test_data = data.TabularDataset.splits(path ='tweet-transformer/1h',\n",
    "                                                   train='test7_v2.csv',\n",
    "                                                   test ='test7_v2.csv',\n",
    "                                                   format='csv',\n",
    "                                                   skip_header = True,\n",
    "                                                   fields=[('tweet_n', TEXT_N),\n",
    "                                                           #('section', SECTION),\n",
    "                                                           #('trend_n', TREND_N),\n",
    "                                                           #('price_n', PRICE_N),\n",
    "                                                           ('label', LABEL)])\n",
    "print(\"„Éá„Éº„ÇøË™≠„ÅøËæº„ÅøÂÆå‰∫Ü\")\n",
    "\n",
    "# ÂçòË™ûËæûÊõ∏„ÅÆ‰ΩúÊàê\n",
    "TEXT_N.build_vocab(train_data, min_freq=2)\n",
    "vocab = TEXT_N.vocab\n",
    "print('ËæûÊõ∏‰ΩúÊàêÂÆå‰∫Ü')\n",
    "\n",
    "# „ÉÜ„Ç≠„Çπ„Éà„ÇíÊï∞ÂÄ§„Éô„ÇØ„Éà„É´Âåñ„ÄÅ„Éê„ÉÉ„ÉÅ„Å´ÂàÜÂâ≤\n",
    "train_iter, test_iter = data.BucketIterator.splits((train_data, test_data),\n",
    "                                                   batch_sizes=(1024, 512))\n",
    "\n",
    "# „É°„É¢„É™Ëß£Êîæ\n",
    "gc.collect()\n",
    "print('„É°„É¢„É™Ëß£Êîæ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83f7afac-54ab-4475-b276-d3b7cd2fa0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# „Éë„É©„É°„Éº„Çø„Éº\n",
    "ntokens = len(vocab)  # size of vocabulary\n",
    "d_model = 512  # embedding dimension\n",
    "nhead   = 8    # number of heads in nn.MultiheadAttention\n",
    "d_hid   = 2048  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 6    # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "dropout = 0.2  # dropout probability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4024d1bf-ade2-4b1a-987c-e759fb32d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer„É¢„Éá„É´„ÅÆÊ¶ÇË¶Å\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 ntoken: int,\n",
    "                 d_model: int,\n",
    "                 nhead: int,\n",
    "                 d_hid: int,\n",
    "                 nlayers: int,\n",
    "                 dropout: float = 0.5):\n",
    "\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.d_model = d_model\n",
    "        self.emb = nn.Embedding(ntoken, d_model, padding_idx=0)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.classifer = nn.Linear(d_model, 3)\n",
    "        #self.logsoftmax = nn.LogSoftmax()\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.emb.weight.data.uniform_(-initrange, initrange)\n",
    "        self.classifer.bias.data.zero_()\n",
    "        self.classifer.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    #„Éá„Éº„Çø„ÅÆÊµÅ„Çå\n",
    "    #def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n",
    "    def forward(self, src: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        \"\"\"\n",
    "        print(src.shape)\n",
    "        embedded = self.emb(src) * math.sqrt(self.d_model)\n",
    "        print(embedded.shape)\n",
    "        pos = self.pos_encoder(embedded)\n",
    "        print(pos.shape)\n",
    "        #encoder_out = self.transformer_encoder(pos, src_mask)\n",
    "        encoder_out = self.transformer_encoder(pos)\n",
    "        print(encoder_out.shape)\n",
    "        x = encoder_out.mean(dim=1)\n",
    "        print(x.shape)\n",
    "        output = self.classifer(x)\n",
    "        print(output.shape)\n",
    "        #output = self.logsoftmax(output)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ccd6b58-81a3-40fe-bb4f-b3d4879c0a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self Attention Mask\n",
    "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
    "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0419fd72-cc71-4ea6-9c03-14f8bc8118a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PositionalEncoding„ÅÆÊ¶ÇË¶Å\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 d_model: int,\n",
    "                 dropout: float = 0.1,\n",
    "                 max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444e1641-7375-4fca-b072-71d317fb4dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 32\n",
    "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        source: Tensor, shape [full_seq_len, batch_size]\n",
    "        i: int\n",
    "\n",
    "    Returns:\n",
    "        tuple (data, target), where data has shape [seq_len, batch_size] and\n",
    "        target has shape [seq_len * batch_size]\n",
    "    \"\"\"\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "347d6607-0b87-4782-af6f-5f4a8f27d895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â≠¶ÁøíÈñãÂßã\n",
      "------------------epoch=0------------------\n",
      "torch.Size([90, 1024])\n",
      "torch.Size([90, 1024, 512])\n",
      "torch.Size([90, 1024, 512])\n",
      "torch.Size([90, 1024, 512])\n",
      "torch.Size([90, 512])\n",
      "torch.Size([90, 3])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (90) to match target batch_size (1024).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xx/b9j_s_jx73s901xznm0f4wy80000gn/T/ipykernel_1947/689253589.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1121\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (90) to match target batch_size (1024)."
     ]
    }
   ],
   "source": [
    "#Ë®ìÁ∑¥ & „ÉÜ„Çπ„Éà\n",
    "\n",
    "epochs = 10\n",
    "model = TransformerModel(ntokens, d_model, nhead, d_hid, nlayers, dropout).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 1e-3\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "print(\"Â≠¶ÁøíÈñãÂßã\")\n",
    "for epoch in range(epochs):\n",
    "    print(f\"------------------{epoch=}------------------\")\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_correct = 0\n",
    "    epoch_count = 0\n",
    "    for idx, batch in enumerate(iter(train_iter)):\n",
    "        predictions = model(batch.tweet_n.to(device))\n",
    "        labels = batch.label.to(device) - 1\n",
    "\n",
    "        loss = criterion(predictions, labels)\n",
    "\n",
    "        correct = predictions.argmax(axis=1) == labels\n",
    "        acc = correct.sum().item() / correct.size(0)\n",
    "\n",
    "        epoch_correct += correct.sum().item()\n",
    "        epoch_count += correct.size(0)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        lr = scheduler.get_last_lr()[0]\n",
    "        scheduler.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_epoch_loss = 0\n",
    "        test_epoch_correct = 0\n",
    "        test_epoch_count = 0\n",
    "\n",
    "        for idx, batch in enumerate(iter(test_iter)):\n",
    "            predictions = model(batch.text.to(device))\n",
    "            labels = batch.label.to(device) - 1\n",
    "            test_loss = criterion(predictions, labels)\n",
    "\n",
    "            correct = predictions.argmax(axis=1) == labels\n",
    "            acc = correct.sum().item() / correct.size(0)\n",
    "\n",
    "            test_epoch_correct += correct.sum().item()\n",
    "            test_epoch_count += correct.size(0)\n",
    "            test_epoch_loss += loss.item()\n",
    "            \n",
    "    elapsed = time.time() - epoch_start_time\n",
    "\n",
    "    print(f\"{epoch_loss=}\")\n",
    "    print(f\"epoch_accuracy: {epoch_correct / epoch_count}\")\n",
    "    print(f\"{test_epoch_loss=}\")\n",
    "    print(f\"test_epoch_accuracy: {test_epoch_correct / test_epoch_count}\")\n",
    "    print(f'time: {elapsed:5.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b9b279-ca38-4d79-a472-ca2529ca9bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf691823-0891-4e28-87ea-82a5dff263ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3844708a-0b51-4389-8cc0-ea15ea89e9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.legacy.data.batch.Batch of size 64]\n",
      "\t[.tweet_n]:[torch.LongTensor of size 63x64]\n",
      "\t[.label]:[torch.LongTensor of size 64]\n"
     ]
    }
   ],
   "source": [
    "train_ = next(iter(train_iter))\n",
    "print(train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e523285-c4c1-4639-ad5a-de22edcd57bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.legacy.data.iterator.BucketIterator at 0x10edfd280>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70129a6d-a08e-48e3-9ef6-6df28035de37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.legacy.data.dataset.TabularDataset at 0x1582845b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd71fa4f-21b5-41e6-aef6-2bd7c8316214",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "l = 0\n",
    "t = 0\n",
    "for batch in train_iter:\n",
    "    l = max(l, batch.label.shape)\n",
    "    t = max(t, batch.tweet_n.shape)\n",
    "print(l,t)\n",
    "'''\n",
    "\n",
    "\n",
    "for batch in train_iter:\n",
    "    print(batch.label.shape)\n",
    "    print(batch.tweet_n.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f4c3dca-aa12-40e2-b75f-259fea071c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['top50', 'cryptocurrency', 'in/out', 'update', 'last', '12', 'hours', '(', 'crypto', 'bitcoin', 'altcoin', ')', 'in', 'out']\n",
      "0\n",
      "['bitcoin', '.', '39üíö', '+159', '.', '43', 'last', '1', 'hour', '(', '+0', '.', '46%', ')', 'üíö', '+219', '.', '3', 'last', '5', 'hours', '(', '+0', '.', '63%', ')', 'üíî', '-845', '.', '02', 'last', '24', 'hours', '(', '-2', '.', '35%', ')', 'bitcoinpriceupdates', 'bitcoin', 'hourlycrypto', 'cryptoupdates', 'cryptopowered', 'api']\n",
      "0\n",
      "['bitcoincurrent', 'price', '35060‚Ç¨', '29561', '.', '01cryptocurrencies', 'blockchain', 'btc']\n",
      "0\n",
      "['gold', '|', '|', 'gold', 'waylong', 'short', 'btc', 'trade8']\n",
      "0\n",
      "['binance', 'activity', 'üîµ', 'bought', 'worth', '47', '.', '1m+', 'usdtüî¥', 'sold', 'worth', '30', '.', '1m+', 'usdtüî¥', 'sold', 'worth', '28', '.', '4m+', 'usdtüîµ', 'bought', 'worth', '23', '.', '9m+', 'usdtcryptocurrency', 'cryptotrading', 'binance', '-']\n",
      "0\n",
      "['price', 'ofspaghetti', 'alla', 'carbonarais', '31', ',', '359', 'satoshisor', '0', '.', '00031359', 'btc1', 'btc', '=', '35', ',', '046', '.', '20', 'usd1', 'usd', '=', '2', ',', '853', 'saton', 'wednesday', ',', '30', 'june', '2021', '07', '00', 'pm', 'cdtbitcoin', 'carbonaraindex']\n",
      "0\n",
      "['u', '.', 's', '.', 'citizens', 'soon', 'able', 'buy', 'bitcoin', 'across', '650', 'banks', 'source', 'from']\n",
      "0\n",
      "['bitmex', 'oi', '507', ',', '181', ',', '300funding', '-0', '.', '0046%24h', 'volume', '1', ',', '364', ',', '658', ',', '900bybit', 'oi', '981', ',', '445', ',', '772funding', '-0', '.', '0119%24h', 'volume', '5', ',', '008', ',', '400', ',', '555okex', 'oi', '453', ',', '739funding', '-0', '.', '0005%24h', 'volume', '5', ',', '087', ',', '213ftx', 'oi', '23', ',', '987', '.', '8485', 'funding', '-0', '.', '0009%24h', 'volume', '89', ',', '589', '.', '6614']\n",
      "0\n",
      "['current', 'bitcoin', 'price', 'usd', ',', '033', '.', '67gbp', '¬£25', ',', '333', '.', '97euro', '‚Ç¨29', ',', '544', '.', '91bitcoin', 'btc', 'btcusd', 'btcgbp', 'btceur', 'crypto', 'cryptocurrency']\n",
      "0\n",
      "['wow', 'bitcoin', 'closed', '!', '!', '!', '!', 'amazing', 'job', 'bulls', '.', 'good', 'days', 'ahead', 'guys', '.']\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for example in train_data:\n",
    "    print(example.label)\n",
    "    print(example.tweet_n)\n",
    "    i+=1\n",
    "    if i==10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47c45f8e-bbca-4afb-9819-989b38d02275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "[torchtext.legacy.data.batch.Batch of size 64]\n",
      "\t[.tweet_n]:[torch.LongTensor of size 49x64]\n",
      "\t[.label]:[torch.LongTensor of size 64]\n",
      "1\n",
      "\n",
      "[torchtext.legacy.data.batch.Batch of size 64]\n",
      "\t[.tweet_n]:[torch.LongTensor of size 45x64]\n",
      "\t[.label]:[torch.LongTensor of size 64]\n",
      "2\n",
      "\n",
      "[torchtext.legacy.data.batch.Batch of size 64]\n",
      "\t[.tweet_n]:[torch.LongTensor of size 79x64]\n",
      "\t[.label]:[torch.LongTensor of size 64]\n",
      "3\n",
      "\n",
      "[torchtext.legacy.data.batch.Batch of size 64]\n",
      "\t[.tweet_n]:[torch.LongTensor of size 57x64]\n",
      "\t[.label]:[torch.LongTensor of size 64]\n",
      "4\n",
      "\n",
      "[torchtext.legacy.data.batch.Batch of size 64]\n",
      "\t[.tweet_n]:[torch.LongTensor of size 63x64]\n",
      "\t[.label]:[torch.LongTensor of size 64]\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for idx, batch in enumerate(iter(train_iter)):\n",
    "    print(idx)\n",
    "    print(batch)\n",
    "    i+=1\n",
    "    if i==5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f85968e-0c98-4671-acba-d4187926195b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pad_sequence(): argument 'sequences' (position 1) must be tuple of Tensors, not BucketIterator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xx/b9j_s_jx73s901xznm0f4wy80000gn/T/ipykernel_949/2789623311.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpad_sequence\u001b[0;34m(sequences, batch_first, padding_value)\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;31m# assuming trailing dimensions and type of all the Tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;31m# in sequences are same and fetching those from sequences[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: pad_sequence(): argument 'sequences' (position 1) must be tuple of Tensors, not BucketIterator"
     ]
    }
   ],
   "source": [
    "rnn.pad_sequence(train_iter).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5f87c5-f3a2-4f3d-bee6-1f940770815d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
