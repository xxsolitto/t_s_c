{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "425ceb85-d9ff-409a-880f-1d0f94c562c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext import data\n",
    "from torchtext.legacy import data\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import datetime\n",
    "import itertools\n",
    "import pickle\n",
    "import sys\n",
    "import copy\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f08f132e-a961-4c15-bc82-e95d150200e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle書き込み\n",
    "def write_pickle(filepath, data):\n",
    "    start_time = time.time()\n",
    "    print(f'writing pickle to \"{filepath}\" ...')    \n",
    "    \n",
    "    with open(filepath, 'wb') as p:\n",
    "        pickle.dump(data,p)\n",
    "    \n",
    "    print(f'end of writeing {time.time()-start_time:6.2f} s')\n",
    "    \n",
    "    del start_time\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d886884-28e4-4f75-9c02-53ae14d05d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle書き込み\n",
    "# ログなしVer\n",
    "def write_pickle_quickly(filepath, data):\n",
    "    with open(filepath, 'wb') as p:\n",
    "        pickle.dump(data,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17a06a96-7d3e-463b-99fd-1af31e09e177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle読み出し\n",
    "def read_pickle(filepath):\n",
    "    start_time = time.time()\n",
    "    print(f'reading pickle from \"{filepath}\" ...')\n",
    "    \n",
    "    with open(filepath, 'rb') as p:\n",
    "        data = pickle.load(p)\n",
    "    \n",
    "    print(f'end of reading {time.time()-start_time:6.2f} s')\n",
    "    \n",
    "    del start_time\n",
    "    gc.collect()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb9cfa57-4527-4b48-bd93-23df0ede2fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle読み出し\n",
    "# ログなしVer\n",
    "def read_pickle_quickly(filepath):\n",
    "    with open(filepath, 'rb') as p:\n",
    "        data = pickle.load(p)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e604666-0df1-4b16-9463-2d7f0f8d03c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading...\n",
      "reading pickle from \"../../external_drive/pickle/vocab.pickle\" ...\n",
      "end of reading   1.86 s\n",
      "Finish!!\n",
      " 1.94 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nv_start = time.time()\\ntokenizer = get_tokenizer(\\'basic_english\\')\\n\\n# data field定義\\nTEXT  = data.Field(sequential=True,\\n                     lower=True,\\n                     batch_first=True, \\n                     tokenize=tokenizer,\\n                     init_token=\\'<cls>\\')\\n\\n# CSVファイルを読み込み、TabularDatasetオブジェクトの作成\\nprint(\"Reading...\")\\nvocab_data = data.TabularDataset(path =\\'tweet-transformer/1d/2021-17_t.csv\\',\\n                                       format=\\'csv\\',\\n                                       skip_header = True,\\n                                       fields=[(\\'tweet\\', TEXT)])\\n\\n# 単語辞書の作成\\nprint(\"Creating vocab...\")\\nTEXT.build_vocab(vocab_data, min_freq=3)\\nvocab = TEXT.vocab\\nprint(f\\'{len(vocab)=}\\')\\n\\nprint(\\'Finish!!\\')\\nprint(f\\'{time.time() - v_start:5.2f} s\\')\\n\\n# メモリ開放\\ndel v_start, vocab_data, tokenizer, TEXT\\ngc.collect()\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vacab作成\n",
    "# テキストを単語で分割\n",
    "\n",
    "v_start = time.time()\n",
    "print(\"Reading...\")\n",
    "vocab = read_pickle('../../external_drive/pickle/vocab.pickle')\n",
    "print('Finish!!')\n",
    "print(f'{time.time() - v_start:5.2f} s')\n",
    "del v_start\n",
    "gc.collect()\n",
    "\n",
    "'''\n",
    "v_start = time.time()\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# data field定義\n",
    "TEXT  = data.Field(sequential=True,\n",
    "                     lower=True,\n",
    "                     batch_first=True, \n",
    "                     tokenize=tokenizer,\n",
    "                     init_token='<cls>')\n",
    "\n",
    "# CSVファイルを読み込み、TabularDatasetオブジェクトの作成\n",
    "print(\"Reading...\")\n",
    "vocab_data = data.TabularDataset(path ='tweet-transformer/1d/2021-17_t.csv',\n",
    "                                       format='csv',\n",
    "                                       skip_header = True,\n",
    "                                       fields=[('tweet', TEXT)])\n",
    "\n",
    "# 単語辞書の作成\n",
    "print(\"Creating vocab...\")\n",
    "TEXT.build_vocab(vocab_data, min_freq=3)\n",
    "vocab = TEXT.vocab\n",
    "print(f'{len(vocab)=}')\n",
    "\n",
    "print('Finish!!')\n",
    "print(f'{time.time() - v_start:5.2f} s')\n",
    "\n",
    "# メモリ開放\n",
    "del v_start, vocab_data, tokenizer, TEXT\n",
    "gc.collect()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70cac4e7-4cf8-4513-9c23-d5d2481c3360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset1の定義\n",
    "# args　：tdf['ids'], tdf['mask']\n",
    "# return：dataset{ids,mask}\n",
    "\n",
    "class CreateDataset1(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x # tdf['ids']\n",
    "        self.y = y # tdf['mask']\n",
    "        \n",
    "    # len(Dataset)で返す値を指定\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    # Dataset[index]で返す値を指定\n",
    "    def __getitem__(self, index):\n",
    "        ids  = self.x[index]\n",
    "        mask = self.y[index]\n",
    "\n",
    "        return {'ids'   : ids,\n",
    "                'mask'  : mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eec91bd8-e6fd-4656-9c2a-b1883d01483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset3の定義\n",
    "# args　：tensor of section, tensor of price, tensor of trend(n+1)\n",
    "# return：dataset3{section, src, target}\n",
    "class CreateDataset3(Dataset):\n",
    "    def __init__(self, x, y, z):\n",
    "        self.x = x # tensor of section\n",
    "        self.y = y # tensor of price\n",
    "        self.z = z # tensor of trend(n+1)\n",
    "        \n",
    "    # len(Dataset)で返す値を指定\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    # Dataset[index]で返す値を指定\n",
    "    def __getitem__(self, index):\n",
    "        section = self.x[index]\n",
    "        src     = self.y[index]\n",
    "        target  = self.z[index]\n",
    "\n",
    "        return {'section': section,\n",
    "                'src'    : src,\n",
    "                'target' : target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f6af1b0-9f00-4a84-96ce-19f35d7685fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor_df()内の関数\n",
    "max_len = 128\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "def tokenize(text):\n",
    "    return tokenizer(text)\n",
    "\n",
    "def text_to_ids(tokenized_text):\n",
    "    ids  = torch.tensor([vocab[word] for word in tokenized_text], dtype=torch.long).unsqueeze(0) # [1,seq_len]\n",
    "    ids  = F.pad(ids, (0 ,max_len-len(tokenized_text)), \"constant\", 0) # [1,max_len]\n",
    "    return ids\n",
    "\n",
    "def ids_to_mask(ids):\n",
    "    mask = (ids==0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74f5c801-1aba-41cd-8098-1ddfdb388109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return df[section.ids,mask]\n",
    "def tensor_df(df):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print('1.text to ids...')\n",
    "    df['tweet(n)'] = df['tweet(n)'].apply(tokenize)\n",
    "    df['ids']      = df['tweet(n)'].apply(text_to_ids)\n",
    "    print('2.ids to mask...')\n",
    "    df['mask']     = df['ids'].apply(ids_to_mask)\n",
    "    df = df.drop(columns=['tweet(n)'])\n",
    "    \n",
    "    print(f'end of df to tensor {time.time()-start_time:6.2f} s')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8da9f9f8-254a-4e69-a3e0-01f1b7293fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return : df[section,ids(n),mask(n)]\n",
    "# sectionごとにtensor連結\n",
    "train_num_section_list = {'1d':181,'12h':363,'4h':1090,'1h':4361,'30m':8722,'15m':17444,'5m':52333}\n",
    "test_num_section_list  = {'1d':31, '12h':61, '4h':182, '1h':727, '30m':1454,'15m':2908, '5m':8723}\n",
    "\n",
    "def separate_section(df):\n",
    "    num_section = train_num_section_list[timespan] + test_num_section_list[timespan]\n",
    "    section_list = []\n",
    "    ids_list  = []\n",
    "    mask_list = []\n",
    "    for i in range (0,num_section):\n",
    "        #pandasのSectionkを抽出　idsとmaskをひとまとまりのtensorに\n",
    "        section_list.append(i)\n",
    "        df_ids = df[df['section'] == i]['ids']\n",
    "        l = df_ids.values.tolist()\n",
    "        x = torch.cat(l, dim=0)\n",
    "        ids_list.append(x)\n",
    "        df_mask = df[df['section'] == i]['mask']\n",
    "        l = df_mask.values.tolist()\n",
    "        x = torch.cat(l, dim=0)\n",
    "        mask_list.append(x)\n",
    "    \n",
    "    df = pd.DataFrame(list(zip(section_list, ids_list, mask_list)), columns = ['section','ids','mask'])\n",
    "    \n",
    "    return df        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ab9cd8d-02a6-45d8-b393-dd6df9d4e6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasetの作成 (ツイート)\n",
    "# 1. df to tensor\n",
    "# 2. separate_section\n",
    "def data_process1(timespan):\n",
    "    print('-'*5 + 'Create dataset_tlist start!!' + '-'*5)\n",
    "\n",
    "    print('Reading...')\n",
    "    dfs = pd.read_csv(f'tweet-transformer/{timespan}/2021-17_s.csv')\n",
    "    df = pd.read_csv(f'tweet-transformer/{timespan}/2021-17_t.csv')\n",
    "    df = df.dropna(how='any')\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    print('df to tensor...')\n",
    "    df = tensor_df(df)\n",
    "    \n",
    "    print('Separating Section...')\n",
    "    df = separate_section(df)\n",
    "        \n",
    "    train_tdf, test_tdf = train_test_split(df, test_size = 1/7, shuffle=False)\n",
    "    \n",
    "    print('Finish!!')\n",
    "    print(f'{len(train_tdf)=}')\n",
    "    print(f'{len(test_tdf)=}')\n",
    "    \n",
    "    return train_tdf, test_tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2da5a352-fff4-4227-8770-91df5e6f9b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasetの作成 (価格)\n",
    "# 1.csv -> 3 tensor\n",
    "# 2.CreateDataset3\n",
    "def data_process2(timespan,n):\n",
    "    print('-'*5 + 'Create dataset_plist start!!' + '-'*5)\n",
    "\n",
    "    print('Reading...')\n",
    "    df  = pd.read_csv(f'tweet-transformer/{timespan}/2021-17_b.csv')\n",
    "    dfs = pd.read_csv(f'tweet-transformer/{timespan}/2021-17_s.csv')\n",
    "\n",
    "    # 説明変数、目的変数\n",
    "    df['trend(n+1)'] = df['trend(n)'].shift(-1)\n",
    "    df['end_price(n)'] = df['open_price(n)'].shift(-1)\n",
    "    if n >= 2:\n",
    "        for i in range(1,n):\n",
    "            df[f'trend(n-{i})'] = df['trend(n)'].shift(i)\n",
    "            df[f'end_price(n-{i})'] = df['end_price(n)'].shift(i)\n",
    "    df = df.drop(columns=['open_price(n)'])\n",
    "    df = df.dropna(how='any')\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # マージして欠損値を含む行を処理\n",
    "    df = pd.merge(dfs, df, on=\"section\", how = 'left')\n",
    "    df = df.reset_index(drop=True)\n",
    "    df['bool'] = df.isnull().any(axis=1)\n",
    "    for i in range(0, len(df)):\n",
    "        if  df['bool'][i] == True:\n",
    "            df['section'][i] = -1\n",
    "    df = df.fillna(-1)\n",
    "    df = df.drop(columns=['bool'])\n",
    "    print(f'{len(df)=}')\n",
    "\n",
    "    train_df, test_df = train_test_split(df, test_size = 1/7, shuffle=False)\n",
    "\n",
    "    # 3つのtensorを作成\n",
    "    print('Creating Dataset3...')\n",
    "    section = torch.tensor(train_df['section'].values)\n",
    "    target  = torch.tensor(train_df['trend(n+1)'].values)\n",
    "    price   = torch.tensor(train_df.drop(columns=['trend(n+1)','section']).values)\n",
    "    train_plist = CreateDataset3(section, price, target)\n",
    "\n",
    "    section = torch.tensor(test_df['section'].values)\n",
    "    target  = torch.tensor(test_df['trend(n+1)'].values)\n",
    "    price   = torch.tensor(test_df.drop(columns=['trend(n+1)','section']).values)\n",
    "    test_plist = CreateDataset3(section, price, target)\n",
    "\n",
    "\n",
    "    print('Finish!!')\n",
    "    print(f'{len(train_plist)=}')\n",
    "    print(f'{len(test_plist)=}')\n",
    "    \n",
    "    del df,dfs,section,price,target,train_df,test_df\n",
    "    gc.collect()\n",
    "    \n",
    "    return train_plist, test_plist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b9b279-ca38-4d79-a472-ca2529ca9bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット作成 & csvに保存\n",
    "# ツイート\n",
    "tlist = ['1d','12h','4h','1h','30m','15m','5m']\n",
    "train_section_list     = {'1d':181,'12h':363,'4h':1090,'1h':4361,'30m':8722,'15m':17444,'5m':52333}\n",
    "test_section_list      = {'1d':31, '12h':61, '4h':182, '1h':727, '30m':1454,'15m':2908, '5m':8723}\n",
    "tlist = ['1h']\n",
    "\n",
    "for timespan in tlist:\n",
    "    print('-'*50 + f'{timespan=}' + '-'*50)\n",
    "    train_tdf, test_tdf = data_process1(timespan)\n",
    "    print(f'{sys.getsizeof(train_tdf)=}')\n",
    "    print(f'{sys.getsizeof(test_tdf)=}')\n",
    "    train_tdf.to_csv(f'../../external_drive/pandas/{timespan}/train_tdf.csv', index=False)\n",
    "    test_tdf.to_csv(f'../../external_drive/pandas/{timespan}/test_tdf.csv', index=False) \n",
    "    write_pickle(f'../../external_drive/pickle/{timespan}/train_tdf.pickle',train_tdf)\n",
    "    write_pickle(f'../../external_drive/pickle/{timespan}/test_tdf.pickle',test_tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296a0e22-4a92-46bf-b967-fbe2ea898514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット作成 & pickleに保存\n",
    "# 価格\n",
    "'''\n",
    "nlist = [1,2,3,4,5,6,7,8,9,10]\n",
    "tlist = ['1d','12h','4h','1h','30m','15m','5m']\n",
    "\n",
    "for timespan, n in itertools.product(tlist, nlist):   \n",
    "\n",
    "    print('-'*50 + f'{timespan=} / {n=}' + '-'*50)\n",
    "    train_plist,test_plist = data_process2(timespan,n)\n",
    "    write_pickle(f'../../external_drive/pickle/{timespan}/train_plist_{n}.pickle',train_plist)\n",
    "    write_pickle(f'../../external_drive/pickle/{timespan}/test_plist_{n}.pickle',test_plist)\n",
    "    \n",
    "    del train_plist, test_plist\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83f7afac-54ab-4475-b276-d3b7cd2fa0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametator for Net\n",
    "ntokens = len(vocab)  # size of vocabulary\n",
    "d_model = 512   # embedding dimension\n",
    "nhead   = 8     # number of heads in nn.MultiheadAttention\n",
    "d_hid   = 2048  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 6     # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "dropout = 0.2   # dropout probability\n",
    "lstm_input_dim  = 16\n",
    "lstm_hidden_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4024d1bf-ade2-4b1a-987c-e759fb32d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer-LSTMモデルの概要\n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 ntoken: int,\n",
    "                 d_model: int,\n",
    "                 nhead: int,\n",
    "                 d_hid: int,\n",
    "                 nlayers: int,\n",
    "                 dropout: float = 0.5):\n",
    "\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(ntoken,\n",
    "                                d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model,\n",
    "                                              dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model,\n",
    "                                                 nhead,\n",
    "                                                 d_hid,\n",
    "                                                 dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers,\n",
    "                                                      nlayers)\n",
    "        self.dense = nn.Linear(d_model,3)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.dense.bias.data.zero_()\n",
    "        self.dense.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    #データの流れ\n",
    "    def forward(self, ids, mask):\n",
    "\n",
    "        # Transformerによるテキストの3値分類           \n",
    "        x = self.embedding(ids) * math.sqrt(self.d_model) # [batch_size, seq_len, d_model]\n",
    "        x = self.pos_encoder(x) # [batch_size, seq_len, d_model]\n",
    "        x = self.transformer_encoder(src=x, src_key_padding_mask=mask) # [batch_size, seq_len, d_model]\n",
    "        #x = self.transformer_encoder(x) # [batch_size, seq_len, d_model]\n",
    "        x = x.mean(dim=1) # [batch_size, d_model]\n",
    "        x = self.dense(x) # [batch_size, 3]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff99cecf-fda2-4d76-8fb4-ef3222c57e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer-LSTMモデルの概要\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 lstm_input_dim: int, \n",
    "                 lstm_hidden_dim: int):\n",
    "\n",
    "        super().__init__()\n",
    "        self.input_dim = lstm_input_dim\n",
    "        self.hidden_dim = lstm_hidden_dim\n",
    "        self.lstm = nn.LSTM(input_size=lstm_input_dim, \n",
    "                            hidden_size=lstm_hidden_dim,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True)\n",
    "        self.dense = nn.Linear(lstm_hidden_dim,3)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.dense.bias.data.zero_()\n",
    "        self.dense.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    #データの流れ\n",
    "    def forward(self, src):\n",
    "            \n",
    "        # LSTMによるテキスト＋価格の３値分類\n",
    "        _, x = self.lstm(src)\n",
    "        print(12, x.size())\n",
    "        x = self.dense(x[0].view(inlist.size(0), -1))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0419fd72-cc71-4ea6-9c03-14f8bc8118a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PositionalEncodingの概要\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 d_model: int,\n",
    "                 dropout: float = 0.1,\n",
    "                 max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        '''\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, seq_len, embedding_dim]\n",
    "        '''\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9367e57a-678c-4d2e-bc15-5fdfd4df01fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0be0225fd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# paramator for training & evaluation\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "softmax = nn.Softmax(dim=1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f2869af-d88f-4720-a8d1-d5836f7f9dd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transformerによるテキストの3値分類\n",
    "tbatch_size_list       = {'1d':256,  '12h':256,  '4h':128,  '1h':128,  '30m':64,  '15m':64,  '5m':32}\n",
    "\n",
    "def text_classifer(t_start,t_end):\n",
    "    tbatch_size = tbatch_size_list[timespan]\n",
    "    train_tdf   = read_pickle_quickly(f'../../external_drive/pickle/{timespan}/train_tdf.pickle')\n",
    "    #prob_section = []\n",
    "    idx_counter_list=[]\n",
    "    \n",
    "    # out : list of tesnsor[neg,neu,pos]\n",
    "    for j in range(t_start,t_end):     \n",
    "        tlist = CreateDataset1(train_tdf['ids'][j], train_tdf['mask'][j])\n",
    "        tbatches = iter(DataLoader(tlist, batch_size=128, shuffle=True))\n",
    "        #p_tbatch = []\n",
    "        idx_counter = -1\n",
    "        # out : list of tensor[batch_size,3]\n",
    "        for idx,batch in enumerate(tbatches):\n",
    "            idx_counter += 1\n",
    "            ids  =  batch['ids'].to(device)  # [batch_size, seq_len]\n",
    "            mask =  torch.t(batch['mask']).to(device) # [seq_len, batch_size]\n",
    "            text_class = model1(ids, mask)  # [batch_size, 3]\n",
    "            prob = softmax(text_class) # [batch_size, 3]\n",
    "            #p_tbatch.append(prob)\n",
    "            \n",
    "            write_pickle_quickly(f'../../external_drive/pickle/temp/{j}_{idx}.pickle',prob.to('cpu'))\n",
    "            del ids, mask, text_class, prob\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        \n",
    "        idx_counter_list.append(idx_counter)\n",
    "#        x = torch.cat(p_tbatch, dim=0) # [batch_size*num_tbatches, 3]\n",
    "#        x = x.sum(dim=0) # [3]\n",
    "#        prob_section.append(x)\n",
    "\n",
    "#    return prob_section\n",
    "    return idx_counter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b08562d-7660-4c23-9a4a-5c2131e961b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_plist_b[j] のtensorと　prob_sectionのtensorを結合\n",
    "def create_tensor(t_start,t_end,idx_counter_list):\n",
    "    prob_section = []\n",
    "    for j in range(t_start,t_end):\n",
    "        p_tbatch = []\n",
    "        for idx in range(0, idx_counter_list[j-t_start]):\n",
    "            prob = read_pickle_quickly(f'../../external_drive/pickle/temp/{j}_{idx}.pickle')\n",
    "            p_tbatch.append(prob)\n",
    "            os.remove(f'../../external_drive/pickle/temp/{j}_{idx}.pickle')\n",
    "        x = torch.cat(p_tbatch, dim=0) # [batch_size*num_tbatches, 3]\n",
    "        print(f'1.{x.size()=}')\n",
    "        x = x.sum(dim=0) # [3]\n",
    "        print(f'2.{x.size()=}')\n",
    "        prob_section.append(x)\n",
    "    \n",
    "    train_plist = read_pickle_quickly(f'../../external_drive/pickle/{timespan}/train_plist_{n}.pickle')\n",
    "    src    = []\n",
    "    target = []\n",
    "    for j in range(t_start,t_end):\n",
    "        if train_plist[j]['section'] != -1:\n",
    "            x = torch.cat(prob_section[j-t_start: j-t_start+n], dim=-1) # [3n]\n",
    "            print(f'3.{x.size()=}')\n",
    "            x = torch.cat((x,train_plist[j]['src']), dim=-1).unsqueeze(0) # [1, 5n]\n",
    "            print(f'4.{x.size()=}')\n",
    "            src.append(x)\n",
    "            target.append(train_plist[j]['target'].unsqueeze(0))\n",
    "    src    = torch.cat(src, dim=0) # [batch_size, 5n]\n",
    "    print(f'5.{src.size()=}')\n",
    "    target = torch.cat(target, dim=-1) # [batch_size]\n",
    "    print(f'6.{target.size()=}')\n",
    "\n",
    "    return src,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a77848dc-a80f-4233-a46d-82d327d1f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "def train(model1,model2, timespan, n):\n",
    "    model1.train()\n",
    "    model2.train()\n",
    "    \n",
    "    log_interval = math.ceil(train_num_batches/30)*10\n",
    "    batch_counter = 0\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_count = 0\n",
    "    \n",
    "    batch_start_time = time.time()\n",
    "    \n",
    "    for i in range(0, train_num_batches):\n",
    "        if i*batch_size-n+1 >= 0:\n",
    "            \n",
    "            if i != (train_num_batches-1):\n",
    "                t_start = i*batch_size-n+1\n",
    "                t_end   = i*batch_size+batch_size\n",
    "            else:\n",
    "                t_start = i*batch_size-n+1\n",
    "                t_end   = train_num_batches\n",
    "            \n",
    "           # prob_section = text_classifer(t_start, t_end)\n",
    "            idx_counter_list = text_classifer(t_start, t_end)\n",
    "            print(idx_counter_list)\n",
    "            src, target = create_tensor(t_start,t_end,idx_counter_list)\n",
    "            #src, target = create_tensor(prob_section)\n",
    "            predictions  = model2(src.to(device))\n",
    "            print('end model2')\n",
    "            prob = softmax(predictions)\n",
    "            targets = target.to(device)\n",
    "            loss = criterion(predictions, targets)\n",
    "\n",
    "            correct = prob.argmax(axis=1) == targets\n",
    "            acc = correct.sum().item() / correct.size(0)\n",
    "\n",
    "            train_correct += correct.sum().item()\n",
    "            train_count += correct.size(0)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            optimizer1.zero_grad()\n",
    "            optimizer2.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer1.step()\n",
    "            optimizer2.step()\n",
    "\n",
    "        batch_counter += 1\n",
    "\n",
    "        if (batch_counter % log_interval == 0 or batch_counter == train_num_batches) and (flag == 1):\n",
    "            lr = scheduler2.get_last_lr()[0]\n",
    "            s_per_batch = (time.time() - batch_start_time) / log_interval\n",
    "            cur_loss = train_loss / log_interval\n",
    "            cur_acc = train_correct / train_count\n",
    "            print(f'| epoch {epoch:3d} | {batch_counter:5d}/{train_num_batches:5d} batches | '\n",
    "                  f'lr {lr:1.5f} | s/batch {s_per_batch:5.2f} | '\n",
    "                  f'loss {cur_loss:5.3f} | accuracy {cur_acc:8.3f}')\n",
    "            total_loss = 0\n",
    "            batch_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93f793e1-ba75-49cf-8fe6-3a497f39d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation (val, test)\n",
    "def evaluate(model1, model2, timespan, n):\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    test_tdf   = read_pickle_quickly(f'../../external_drive/pickle/{timespan}/test_tdf.pickle')\n",
    "    test_plist = read_pickle_quickly(f'../../external_drive/pickle/{timespan}/test_plist_{n}.pickle')    \n",
    "    \n",
    "    eval_loss = 0\n",
    "    eval_correct = 0\n",
    "    eval_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, test_num_batches):\n",
    "            if i != (train_num_batches-1):\n",
    "                t_start = i*batch_size-n+1\n",
    "                t_end   = i*batch_size+batch_size\n",
    "            else:\n",
    "                t_start = i*batch_size-n+1\n",
    "                t_end   = train_num_batches\n",
    "        \n",
    "            prob_section = text_classifer(t_start, t_end)\n",
    "            src, target = create_tensor(prob_section)\n",
    "            predictions  = model2(src.to(device))\n",
    "            prob = softmax(predictions)\n",
    "            targets = target.to(device)\n",
    "            loss = criterion(predictions, targets)\n",
    "\n",
    "            correct = prob.argmax(axis=1) == targets\n",
    "            eval_acc = correct.sum().item() / correct.size(0)\n",
    "\n",
    "            eval_correct += correct.sum().item()\n",
    "            eval_count += correct.size(0)\n",
    "            eval_loss += loss.item()\n",
    "        \n",
    "    print(f'| loss {eval_loss:5.3f}| accuracy {eval_acc:8.3f} ')\n",
    "     \n",
    "    return eval_loss, eval_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "499797d0-d06b-4c55-8768-3def2b2ee0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------timespan='1h' / n=5--------------------------------------------------\n",
      "2021-11-08 08:41:04.949844\n",
      "*********************************************training start*********************************************\n",
      "[7, 8, 10, 10, 13, 10, 9, 9, 40, 39, 36, 35, 67, 49, 40, 39, 33, 26, 22, 18, 16, 16, 14, 13, 12, 28, 20, 26, 23, 20, 18, 19, 23, 24, 24, 25]\n",
      "1.x.size()=torch.Size([896, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([1024, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([1280, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([1280, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([1664, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([1280, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([1152, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([1152, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([5120, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([4992, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([4608, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([4480, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([8576, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([6272, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([5120, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([4992, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([4224, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([3328, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([2816, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([2304, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([2048, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([2048, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([1792, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([1664, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([1536, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([3584, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([2560, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([3328, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([2944, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([2560, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([2304, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([2432, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([2944, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([3072, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([3072, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "1.x.size()=torch.Size([3200, 3])\n",
      "2.x.size()=torch.Size([3])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([15])\n",
      "4.x.size()=torch.Size([1, 25])\n",
      "3.x.size()=torch.Size([12])\n",
      "4.x.size()=torch.Size([1, 22])\n",
      "3.x.size()=torch.Size([9])\n",
      "4.x.size()=torch.Size([1, 19])\n",
      "3.x.size()=torch.Size([6])\n",
      "4.x.size()=torch.Size([1, 16])\n",
      "3.x.size()=torch.Size([3])\n",
      "4.x.size()=torch.Size([1, 13])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Got 25 and 22 in dimension 1 (The offending index is 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-71e7671f5fc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimespan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimespan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-f369f22c0eee>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model1, model2, timespan, n)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0midx_counter_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_classifer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_counter_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_end\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx_counter_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;31m#src, target = create_tensor(prob_section)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mpredictions\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-3f00bfde895c>\u001b[0m in \u001b[0;36mcreate_tensor\u001b[0;34m(t_start, t_end, idx_counter_list)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_plist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0msrc\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch_size, 5n]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'5.{src.size()=}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Got 25 and 22 in dimension 1 (The offending index is 32)"
     ]
    }
   ],
   "source": [
    "# main\n",
    "nlist = [1,2,3,4,5,6,7,8,9,10]\n",
    "tlist = ['1d','12h','4h','1h','30m','15m','5m']\n",
    "batch_size_list        = {'1d':4,  '12h':8,  '4h':16,  '1h':32,  '30m':64,  '15m':128,  '5m':256}\n",
    "train_num_section_list = {'1d':181,'12h':363,'4h':1090,'1h':4361,'30m':8722,'15m':17444,'5m':52333}\n",
    "test_num_section_list  = {'1d':31, '12h':61, '4h':182, '1h':727, '30m':1454,'15m':2908, '5m':8723}\n",
    "train_num_batches_list = {'1d':46, '12h':46, '4h':69,  '1h':137, '30m':137, '15m':69,   '5m':103}\n",
    "test_num_batches_list  = {'1d':8,  '12h':8,  '4h':12,  '1h':23,  '30m':23,  '15m':12,   '5m':18}\n",
    "\n",
    "aculist = {}\n",
    "\n",
    "nlist = [5]\n",
    "tlist = ['1h']\n",
    "\n",
    "for timespan, n in itertools.product(tlist, nlist):\n",
    "\n",
    "    print('-'*50 + f'{timespan=} / {n=}' + '-'*50)\n",
    "    train_num_section = train_num_section_list[timespan]\n",
    "    test_num_section  = test_num_section_list[timespan]\n",
    "    train_num_batches = train_num_batches_list[timespan]\n",
    "    test_num_batches  = test_num_batches_list[timespan]\n",
    "    batch_size=batch_size_list[timespan]\n",
    "\n",
    "    lr = 1e-3\n",
    "    model1 = Transformer(ntokens, d_model, nhead, d_hid, nlayers, dropout).to(device)\n",
    "    optimizer1 = torch.optim.Adam(model1.parameters(), lr=lr)\n",
    "    scheduler1 = torch.optim.lr_scheduler.StepLR(optimizer1, 1.0, gamma=0.95)\n",
    "    model2 = LSTM(lstm_input_dim, lstm_hidden_dim).to(device)\n",
    "    optimizer2 = torch.optim.Adam(model2.parameters(), lr=lr)\n",
    "    scheduler2 = torch.optim.lr_scheduler.StepLR(optimizer2, 1.0, gamma=0.95)\n",
    "    best_val_loss = float('inf')\n",
    "    epochs = 1\n",
    "    best_model = None\n",
    "\n",
    "    dt_start = datetime.datetime.now()\n",
    "    print(datetime.datetime.now())\n",
    "    print('*'*45 + 'training start' + '*'*45)\n",
    "\n",
    "    # training & test roop\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        train(model1, model2, timespan, n)\n",
    "        val_loss, val_acc = evaluate(model1, model2, timespan, n)\n",
    "\n",
    "        print('-' * 95)\n",
    "        print(f'| end of epoch {epoch:3d} | time: {time.time()-epoch_start_time:5.2f}s | '\n",
    "              f'val loss：{val_loss:5.3f} | val accuracy：{val_acc:8.3f}')\n",
    "        print('-' * 95)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model1 = copy.deepcopy(model1)\n",
    "            best_model2 = copy.deepcopy(model2)\n",
    "\n",
    "        scheduler1.step()\n",
    "        scheduler2.step()\n",
    "\n",
    "        del epoch_start_time, val_loss, val_acc\n",
    "        gc.collect()\n",
    "\n",
    "    dt_end = datetime.datetime.now()\n",
    "    elapsed = dt_end - dt_start\n",
    "    print(datetime.datetime.now())    \n",
    "    print('*'*30 + f'Finish! training time：{elapsed:8.2f}s' + '*'*30)\n",
    "\n",
    "    # test\n",
    "    test_loss, test_acc = evaluate(best_model1, best_model2, timespan, n)\n",
    "    print('=' * 89)\n",
    "    print(f'| End of training | test loss：{test_loss:5.3f} | '\n",
    "          f'test accuracy：{test_acc:8.3f}')\n",
    "    print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92469a24-b45c-4cff-b27a-26dc385dbc36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf691823-0891-4e28-87ea-82a5dff263ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = 'cpu'\n",
    "#device = torch.device(\"cuda:1\")\n",
    "print(device)\n",
    "#torch.cuda.is_initialized()\n",
    "#torch.cuda.ipc_collect()\n",
    "#torch.cuda.empty_cache()\n",
    "#gc.collect()\n",
    "#print(f'{sys.getsizeof(l)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26b8163e-c26d-4c9d-8b9f-ff6bb147d50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device0 = torch.device(\"cuda:0\")\n",
    "device1 = torch.device(\"cuda:1\")\n",
    "print(torch.cuda.is_available())\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b64162-10e7-4073-a0fb-671b3adc86be",
   "metadata": {},
   "outputs": [],
   "source": [
    "timespan = '1h'    \n",
    "print('-'*50 + f'{timespan=}' + '-'*50)\n",
    "train_tdf, test_tdf = data_process1(timespan)\n",
    "print(f'{sys.getsizeof(train_tdf)=}')\n",
    "print(f'{sys.getsizeof(test_tdf)=}')\n",
    "train_tdf.to_csv(f'../../external_drive/pandas/{timespan}/train_tdf.csv', index=False)\n",
    "test_tdf.to_csv(f'../../external_drive/pandas/{timespan}/test_tdf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "735d693a-aefc-40bb-b448-6c0512e78d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5410, -0.2934, -2.1788],\n",
      "        [ 0.5684, -1.0845, -1.3986],\n",
      "        [ 0.4033,  0.8380, -0.7193]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3,3).to(device)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "addd2e09-5a70-4c62-bcce-ed9401524fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5410, -0.2934, -2.1788],\n",
      "        [ 0.5684, -1.0845, -1.3986],\n",
      "        [ 0.4033,  0.8380, -0.7193]])\n"
     ]
    }
   ],
   "source": [
    "print(a.to('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75fdd737-c2f2-4bca-973c-7115c7abcfe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ed59e1-c155-4a1f-bd0a-88ba61dc7671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
