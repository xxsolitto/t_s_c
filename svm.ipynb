{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b9f439-66e1-4aa0-b7a2-6a32aaa8d15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gc\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40591286-361c-46d8-b061-76c9d44a371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ読み込み、各月の結合、欠損値を含む行の削除\n",
    "# 1 : neg_count, neu_count, pos_count\n",
    "def read_data1(timespan,n):\n",
    "    print(\"[read開始]\\n\")\n",
    "    \n",
    "    files = [f'tweet-svm/{timespan}/2021-01.csv',\n",
    "             f'tweet-svm/{timespan}/2021-02.csv',\n",
    "             f'tweet-svm/{timespan}/2021-03.csv',\n",
    "             f'tweet-svm/{timespan}/2021-04.csv',\n",
    "             f'tweet-svm/{timespan}/2021-05.csv',\n",
    "             f'tweet-svm/{timespan}/2021-06.csv']\n",
    "    datas = []\n",
    "    df = pd.DataFrame()\n",
    "    for file in files:\n",
    "        data = pd.read_csv(file, usecols = ['section','neg_count','neu_count','pos_count','open_price','trend'])\n",
    "        datas.append(data)\n",
    "\n",
    "    # ファイルの結合\n",
    "    df = pd.concat(datas).reset_index(drop=True)\n",
    "    df = df.drop(columns=['section'])\n",
    "    \n",
    "    # カラム名変更(区間No.割り当て)\n",
    "    df = df.rename(columns={\"neg_count\":\"neg_count(n)\", \n",
    "                        \"neu_count\":\"neu_count(n)\", \n",
    "                        \"pos_count\":\"pos_count(n)\", \n",
    "                        \"open_price\":\"open_price(n)\",\n",
    "                        \"trend\":\"trend(n)\"})\n",
    "    \n",
    "    print('欠損値削除前の総データ数：{}'.format(len(df)))\n",
    "    \n",
    "    # 目的変数\n",
    "    df['trend(n+1)'] = df['trend(n)'].shift(-1)\n",
    "\n",
    "    # 説明変数\n",
    "    df['open_price(n+1)'] = df['open_price(n)'].shift(-1)\n",
    "    if n >= 2:\n",
    "        for i in range(1,n):\n",
    "            df[f'neg_count(n-{i})'] = df['neg_count(n)'].shift(i)\n",
    "            df[f'neu_count(n-{i})'] = df['neu_count(n)'].shift(i)\n",
    "            df[f'pos_count(n-{i})'] = df['pos_count(n)'].shift(i)\n",
    "            df[f'trend(n-{i})'] = df['trend(n)'].shift(i)\n",
    "            if i==n-1: break\n",
    "            df[f'open_price(n-{i})'] = df['open_price(n)'].shift(i)\n",
    "    else:\n",
    "        df = df.drop(columns=['open_price(n)'])\n",
    "\n",
    "    # 欠損値を含む行を削除\n",
    "    df = df.dropna(how='any')\n",
    "    print('欠損値削除後の総データ数：{}\\n'.format(len(df)))\n",
    "    \n",
    "    print(\"[read終了]\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82c8242-6075-4c0e-9be0-3ea83a42d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ読み込み、各月の結合、欠損値を含む行の削除\n",
    "# 2 : com_ave, tweet_cont\\n\n",
    "def read_data2(timespan,n):\n",
    "    print(\"[read開始]\\n\")\n",
    "    \n",
    "    files = [f'tweet-svm/{timespan}/2021-01.csv',\n",
    "             f'tweet-svm/{timespan}/2021-02.csv',\n",
    "             f'tweet-svm/{timespan}/2021-03.csv',\n",
    "             f'tweet-svm/{timespan}/2021-04.csv',\n",
    "             f'tweet-svm/{timespan}/2021-05.csv',\n",
    "             f'tweet-svm/{timespan}/2021-06.csv']\n",
    "    datas = []\n",
    "    df = pd.DataFrame()\n",
    "    for file in files:\n",
    "        data = pd.read_csv(file, usecols = ['section','com_ave','tweet_count','open_price','trend'])\n",
    "        datas.append(data)\n",
    "\n",
    "    # ファイルの結合\n",
    "    df = pd.concat(datas).reset_index(drop=True)\n",
    "    df = df.drop(columns=['section'])\n",
    "    \n",
    "    # カラム名変更(区間No.割り当て)\n",
    "    df = df.rename(columns={\"com_ave\":\"com_ave(n)\", \n",
    "                            \"tweet_count\":\"tweet_count(n)\", \n",
    "                            \"open_price\":\"open_price(n)\",\n",
    "                            \"trend\":\"trend(n)\"})\n",
    "    \n",
    "    print('欠損値削除前の総データ数：{}'.format(len(df)))\n",
    "    \n",
    "    # 目的変数\n",
    "    df['trend(n+1)'] = df['trend(n)'].shift(-1)\n",
    "\n",
    "    # 説明変数\n",
    "    df['open_price(n+1)'] = df['open_price(n)'].shift(-1)\n",
    "    if n >= 2:\n",
    "        for i in range(1,n):\n",
    "            df[f'com_ave(n-{i})'] = df['com_ave(n)'].shift(i)\n",
    "            df[f'tweet_count(n-{i})'] = df['tweet_count(n)'].shift(i)\n",
    "            df[f'trend(n-{i})'] = df['trend(n)'].shift(i)\n",
    "            if i==n-1: break\n",
    "            df[f'open_price(n-{i})'] = df['open_price(n)'].shift(i)\n",
    "    else:\n",
    "        df = df.drop(columns=['open_price(n)'])\n",
    "\n",
    "    # 欠損値を含む行を削除\n",
    "    df = df.dropna(how='any')\n",
    "    print('欠損値削除後の総データ数：{}\\n'.format(len(df)))\n",
    "    \n",
    "    print(\"[read終了]\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6270338f-bd80-4678-8f05-9f0b5114aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ読み込み、各月の結合、欠損値を含む行の削除\n",
    "# 3 : all\n",
    "def read_data3(timespan,n):\n",
    "    print(\"[read開始]\\n\")\n",
    "    \n",
    "    files = [f'tweet-svm/{timespan}/2021-01.csv',\n",
    "             f'tweet-svm/{timespan}/2021-02.csv',\n",
    "             f'tweet-svm/{timespan}/2021-03.csv',\n",
    "             f'tweet-svm/{timespan}/2021-04.csv',\n",
    "             f'tweet-svm/{timespan}/2021-05.csv',\n",
    "             f'tweet-svm/{timespan}/2021-06.csv']\n",
    "    datas = []\n",
    "    df = pd.DataFrame()\n",
    "    for file in files:\n",
    "        data = pd.read_csv(file)\n",
    "        datas.append(data)\n",
    "\n",
    "    # ファイルの結合\n",
    "    df = pd.concat(datas).reset_index(drop=True)\n",
    "    df = df.drop(columns=['section'])\n",
    "    \n",
    "    # カラム名変更(区間No.割り当て)\n",
    "    df = df.rename(columns={\"neg_count\":\"neg_count(n)\", \n",
    "                            \"neu_count\":\"neu_count(n)\", \n",
    "                            \"pos_count\":\"pos_count(n)\",\n",
    "                            \"com_ave\":\"com_ave(n)\", \n",
    "                            \"tweet_count\":\"tweet_count(n)\", \n",
    "                            \"open_price\":\"open_price(n)\",\n",
    "                            \"trend\":\"trend(n)\"})\n",
    "    \n",
    "    print('欠損値削除前の総データ数：{}'.format(len(df)))\n",
    "    \n",
    "    # 目的変数\n",
    "    df['trend(n+1)'] = df['trend(n)'].shift(-1)\n",
    "\n",
    "    # 説明変数\n",
    "    df['open_price(n+1)'] = df['open_price(n)'].shift(-1)\n",
    "    if n >= 2:\n",
    "        for i in range(1,n):\n",
    "            df[f'neg_count(n-{i})'] = df['neg_count(n)'].shift(i)\n",
    "            df[f'neu_count(n-{i})'] = df['neu_count(n)'].shift(i)\n",
    "            df[f'pos_count(n-{i})'] = df['pos_count(n)'].shift(i)\n",
    "            df[f'com_ave(n-{i})'] = df['com_ave(n)'].shift(i)\n",
    "            df[f'tweet_count(n-{i})'] = df['tweet_count(n)'].shift(i)\n",
    "            df[f'trend(n-{i})'] = df['trend(n)'].shift(i)\n",
    "            if i==n-1: break\n",
    "            df[f'open_price(n-{i})'] = df['open_price(n)'].shift(i)\n",
    "    else:\n",
    "        df = df.drop(columns=['open_price(n)'])\n",
    "\n",
    "    # 欠損値を含む行を削除\n",
    "    df = df.dropna(how='any')\n",
    "    print('欠損値削除後の総データ数：{}\\n'.format(len(df)))\n",
    "    \n",
    "    print(\"[read終了]\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd10fa8-f101-47ed-94f7-cbcf7bd3d4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# スケーリング x' = (x - xmin)/(xmax - xmin)\n",
    "def scaling(x_train,x_test):\n",
    "    print(\"[scaling開始]\")\n",
    "    \n",
    "    scaler = MinMaxScaler().fit(x_train)\n",
    "\n",
    "    x_train_scaled = scaler.transform(x_train)\n",
    "    x_test_scaled  = scaler.transform(x_test)\n",
    "    \n",
    "    print(\"[scalig終了]\")\n",
    "    \n",
    "    return x_train_scaled, x_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fef964e-f150-4763-8763-53a23ec1be4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習 One-versus-the-rest\n",
    "# Default ver. C=1, gamma=auto\n",
    "def default_svm(x_train, y_train, x_test):\n",
    "    print(\"[学習開始(Default)]\")\n",
    "    \n",
    "    model = OneVsRestClassifier(SVC())\n",
    "    model.fit(x_train, y_train)\n",
    "    pred_y = model.predict(x_test)\n",
    "    \n",
    "    print(\"[学習終了(Default)]\\n\")\n",
    "    \n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe7df80-d796-4cb4-a428-36e16732e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C,gammmaの最適値探索ver.\n",
    "def best_svm(x_train, y_train, x_test):\n",
    "    model = OneVsRestClassifier(SVC())\n",
    "    C_params = np.logspace(-4, 4, 5) #10^(-4) ~ 10^4 までで均等に5つの値\n",
    "    gamma_params = np.logspace(-4, 4, 5)\n",
    "\n",
    "    parameters = {'estimator__C': C_params,\n",
    "                  'estimator__gamma': gamma_params}\n",
    "\n",
    "    model_tuning = GridSearchCV(estimator = model,\n",
    "                                param_grid = parameters,\n",
    "                                n_jobs = -1,\n",
    "                                verbose = 3\n",
    "    )\n",
    "    model_tuning.fit(x_train, y_train)\n",
    "    pred_y2 = model_tuning.predict(test_x)\n",
    "\n",
    "    # Best parameter\n",
    "    model_tuning.best_params_\n",
    "    \n",
    "    return pred_y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c862ef-412d-42f1-9d6f-7dece9ea919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "# 部分実行\n",
    "alist = {1:'neg_count, neu_count, pos_count',\n",
    "         2:'com_ave, tweet_cont',\n",
    "         3:'all'}\n",
    "print(\"学習に用いる感情データの種類\\n1 : neg_count, neu_count, pos_count\\n2 : com_ave, tweet_cont\\n3 : all\")\n",
    "a = int(input())\n",
    "print(\"学習に用いるデータの範囲\\n(例1) n = 1 → 区間[n]\\n(例2) n = 2 → 区間[n-1, n]\")\n",
    "n = int(input())\n",
    "\n",
    "tlist = ['1d','12h','4h','1h','30m','15m','5m']\n",
    "aculist = {}\n",
    "\n",
    "for timespan in tlist:\n",
    "    print(\"********************{}：開始********************\\n\".format(timespan))\n",
    "    dt_start = datetime.datetime.now()\n",
    "    print(f'開始時刻：{dt_start}\\n')\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    #データの読み込み\n",
    "    if a == 1:\n",
    "        data = read_data1(timespan,n)\n",
    "    else:\n",
    "        data = read_data2(timespan,n)\n",
    "\n",
    "    # 説明変数、目的変数をセット\n",
    "    x = data.iloc[:, data.columns!='trend(n+1)']\n",
    "    y = data.loc[:, 'trend(n+1)']\n",
    "\n",
    "    #データを訓練用とテスト用に分割\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/6, random_state=0)\n",
    "\n",
    "    # スケーリング\n",
    "    x_train_scaled, x_test_scaled = scaling(x_train, x_test)\n",
    "\n",
    "    # 学習\n",
    "    y_pred = default_svm(x_train_scaled, y_train, x_test_scaled)\n",
    "\n",
    "    # 結果表示\n",
    "    print ('accuracy(Default) : {:.5f}\\n'.format(accuracy_score(y_test, y_pred)))\n",
    "    #print ('最適地探索: {:.5f}'.format(accuracy_score(test_y, pred_y2)))\n",
    "    \n",
    "    # 混同行列\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # precision, recall, f1-score, support\n",
    "    print(classification_report(y_test, y_pred, target_names = ['neg','neu','pos']))\n",
    "    \n",
    "    dt_end = datetime.datetime.now()\n",
    "    print(f'終了時刻：{dt_end}\\n')\n",
    "    \n",
    "    # 結果を格納\n",
    "    aculist[f'{timespan}'] = accuracy_score(y_test, y_pred)\n",
    "    df_log = pd.read_csv('tweet-svm/svm_log.csv')\n",
    "    s = pd.Series([dt_start,\n",
    "                   dt_end,\n",
    "                   timespan,\n",
    "                   alist[a],\n",
    "                   n,\n",
    "                   len(x.columns.values),\n",
    "                   len(data),\n",
    "                   len(y_train),\n",
    "                   len(y_test),\n",
    "                   accuracy_score(y_test, y_pred),\n",
    "                   confusion_matrix(y_test, y_pred),\n",
    "                   classification_report(y_test, y_pred,target_names=['neg','neu','pos'], output_dict=True)],\n",
    "            index=['start_time',\n",
    "                   'end_time',\n",
    "                   'timespan',\n",
    "                   'kind_of_data',\n",
    "                   'range_of_data',\n",
    "                   'attribute',\n",
    "                   'all_data',\n",
    "                   'training_data',\n",
    "                   'test_data',\n",
    "                   'accuracy',\n",
    "                   'confusion_matrix',\n",
    "                   'score_report'])\n",
    "    df_log = df_log.append(s, ignore_index=True)\n",
    "    df_log.to_csv('tweet-svm/svm_log.csv',index=False)\n",
    "    \n",
    "    # メモリ開放\n",
    "    del data,x,y,x_train,x_test,y_train,y_test,x_train_scaled,x_test_scaled,y_pred,dt_start,dt_end,df_log\n",
    "    gc.collect()\n",
    "    \n",
    "    print(\"********************{}：終了********************\\n\".format(timespan))\n",
    "    \n",
    "print(f'正答率\\n{aculist}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e0ea19-6a8e-4d58-bf94-3ba41258d115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "# all実行 (n=1~3, a=1~10の30通り)\n",
    "alist = {1:'neg_count, neu_count, pos_count',\n",
    "         2:'com_ave, tweet_cont',\n",
    "         3:'all'}\n",
    "print(\"学習に用いる感情データの種類 a\\n1 : neg_count, neu_count, pos_count\\n2 : com_ave, tweet_cont\\n3 : all\")\n",
    "print(\"学習に用いるデータの範囲 n\\n(例1) n = 1 → 区間[n]\\n(例2) n = 2 → 区間[n-1, n]\")\n",
    "alist_ = [1,2,3]\n",
    "nlist = [1,2,3,4,5,6,7,8,9,10]\n",
    "tlist = ['1d','12h','4h','1h','30m','15m','5m']\n",
    "aculist = {}\n",
    "for a in alist_:\n",
    "    for n in nlist:\n",
    "        for timespan in tlist:\n",
    "            print(\"********************{}：開始********************\\n\".format(timespan))\n",
    "            dt_start = datetime.datetime.now()\n",
    "            print(f'開始時刻：{dt_start}\\n')\n",
    "\n",
    "            print(f'(a,n) = ({a},{n})')\n",
    "\n",
    "            result = []\n",
    "\n",
    "            #データの読み込み\n",
    "            if a == 1:\n",
    "                data = read_data1(timespan,n)\n",
    "            else:\n",
    "                data = read_data2(timespan,n)\n",
    "\n",
    "            # 説明変数、目的変数をセット\n",
    "            x = data.iloc[:, data.columns!='trend(n+1)']\n",
    "            y = data.loc[:, 'trend(n+1)']\n",
    "\n",
    "            #データを訓練用とテスト用に分割\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/6, random_state=0)\n",
    "\n",
    "            # スケーリング\n",
    "            x_train_scaled, x_test_scaled = scaling(x_train, x_test)\n",
    "\n",
    "            # 学習\n",
    "            y_pred = default_svm(x_train_scaled, y_train, x_test_scaled)\n",
    "\n",
    "            # 結果表示\n",
    "            print ('accuracy(Default) : {:.5f}\\n'.format(accuracy_score(y_test, y_pred)))\n",
    "            #print ('最適地探索: {:.5f}'.format(accuracy_score(test_y, pred_y2)))\n",
    "\n",
    "            # 混同行列\n",
    "            print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "            # precision, recall, f1-score, support\n",
    "            print(classification_report(y_test, y_pred, target_names = ['neg','neu','pos']))\n",
    "\n",
    "            dt_end = datetime.datetime.now()\n",
    "            print(f'終了時刻：{dt_end}\\n')\n",
    "\n",
    "            # 結果を格納\n",
    "            aculist[f'{timespan}'] = accuracy_score(y_test, y_pred)\n",
    "            df_log = pd.read_csv('tweet-svm/svm_log.csv')\n",
    "            s = pd.Series([dt_start,\n",
    "                           dt_end,\n",
    "                           timespan,\n",
    "                           alist[a],\n",
    "                           n,\n",
    "                           len(x.columns.values),\n",
    "                           len(data),\n",
    "                           len(y_train),\n",
    "                           len(y_test),\n",
    "                           accuracy_score(y_test, y_pred),\n",
    "                           confusion_matrix(y_test, y_pred),\n",
    "                           classification_report(y_test, y_pred,target_names=['neg','neu','pos'], output_dict=True)],\n",
    "                    index=['start_time',\n",
    "                           'end_time',\n",
    "                           'timespan',\n",
    "                           'kind_of_data',\n",
    "                           'range_of_data',\n",
    "                           'attribute',\n",
    "                           'all_data',\n",
    "                           'training_data',\n",
    "                           'test_data',\n",
    "                           'accuracy',\n",
    "                           'confusion_matrix',\n",
    "                           'score_report'])\n",
    "            df_log = df_log.append(s, ignore_index=True)\n",
    "            df_log.to_csv('tweet-svm/svm_log.csv',index=False)\n",
    "\n",
    "            # メモリ開放\n",
    "            del data,x,y,x_train,x_test,y_train,y_test,x_train_scaled,x_test_scaled,y_pred,dt_start,dt_end,df_log\n",
    "            gc.collect()\n",
    "\n",
    "            print(\"********************{}：終了********************\\n\".format(timespan))\n",
    "    \n",
    "print(f'正答率\\n{aculist}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1d61a57-6bde-4737-ac44-b2dd34c3ef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log リセット\n",
    "'''\n",
    "df = pd.DataFrame(columns=['start_time',\n",
    "                   'end_time',\n",
    "                   'timespan',\n",
    "                   'kind_of_data',\n",
    "                   'range_of_data',\n",
    "                   'attribute',\n",
    "                   'all_data',\n",
    "                   'training_data',\n",
    "                   'test_data',\n",
    "                   'accuracy',\n",
    "                   'confusion_matrix',\n",
    "                   'score_report'])\n",
    "df.to_csv('tweet-svm/svm_log.csv',index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ace7a6d-c9ba-468f-9ebb-d24e193ec262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
