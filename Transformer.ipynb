{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "425ceb85-d9ff-409a-880f-1d0f94c562c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Optional, List, Tuple\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import LayerNorm\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.nn import TransformerDecoder, TransformerDecoderLayer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fb95ca3-9d86-4504-b6fa-31b7a96a2ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    '''Transformer model.\n",
    "    \n",
    "        Args:\n",
    "            d_model      : encoder/decoder inputsの特徴量数\n",
    "            nhead        : Multi-head Attentionのヘッド数\n",
    "            nhid         : feedforward neural networkの次元数\n",
    "            nlayers      : encoder内のsub-encoder-layerの数\n",
    "            dropout      : ドロップアウト率\n",
    "            activation   : 活性化関数\n",
    "            use_src_mask : encoderで時系列マスクを適用するか\n",
    "            cat_embs     : 各カテゴリ変数におけるカテゴリ数とembedding次元数\n",
    "            fc_dims      : decoder outputsに対するfeedforward neural networkの次元数\n",
    "            device       : cpu or gpu\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "                 d_model: int = 512,\n",
    "                 nhead: int = 8,\n",
    "                 nhid: int = 2048,\n",
    "                 nlayers: int = 6,\n",
    "                 dropout: float = 0.1,\n",
    "                 activation: str = \"relu\",\n",
    "                 use_src_mask: bool = False,\n",
    "                 cat_embs: Optional[List[Tuple[int, int]]] = None,\n",
    "                 fc_dims: Optional[List[int]] = None,\n",
    "                 device: Optional[bool] = None,):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        if device is None:\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        if cat_embs is not None:\n",
    "            self.cat_embs = [\n",
    "                nn.Embedding(n_items, emb_size)\n",
    "                if emb_size != 0\n",
    "                else nn.Embedding(n_items, n_items)\n",
    "                for n_items, emb_size in cat_embs\n",
    "            ]\n",
    "            for i, (n_items, emb_size) in enumerate(cat_embs):\n",
    "                if emb_size == 0:\n",
    "                    self.cat_embs[i].weight.data = torch.eye(\n",
    "                        n_items, requires_grad=False\n",
    "                    )\n",
    "                    for param in self.cat_embs[i].parameters():\n",
    "                        param.requires_grad = False\n",
    "\n",
    "            total_cat_emb_size = np.array(\n",
    "                [\n",
    "                    emb_size if emb_size != 0 else n_items\n",
    "                    for n_items, emb_size in cat_embs\n",
    "                ]\n",
    "            ).sum()\n",
    "        else:\n",
    "            self.cat_embs = None\n",
    "            total_cat_emb_size = 0\n",
    "\n",
    "        self.tgt_mask = None\n",
    "        self.src_mask = None\n",
    "        self.use_src_mask = use_src_mask\n",
    "        self.pos_encoder = PositionalEncoding(d_model + total_cat_emb_size, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(\n",
    "            d_model + total_cat_emb_size, nhead, nhid, dropout, activation\n",
    "        )\n",
    "        encoder_norm = LayerNorm(d_model + total_cat_emb_size)\n",
    "        self.transformer_encoder = TransformerEncoder(\n",
    "            encoder_layers, nlayers, encoder_norm\n",
    "        )\n",
    "\n",
    "        decoder_layers = TransformerDecoderLayer(\n",
    "            d_model + total_cat_emb_size, nhead, nhid, dropout, activation\n",
    "        )\n",
    "        decoder_norm = LayerNorm(d_model + total_cat_emb_size)\n",
    "        self.transformer_decoder = TransformerDecoder(\n",
    "            decoder_layers, nlayers, decoder_norm\n",
    "        )\n",
    "\n",
    "        if fc_dims is None:\n",
    "            fc_dims = []\n",
    "\n",
    "        if len(fc_dims) > 0:\n",
    "            fc_layers = []\n",
    "            for i, hdim in enumerate(fc_dims):\n",
    "                if i != 0:\n",
    "                    fc_layers.append(nn.Linear(fc_dims[i - 1], hdim))\n",
    "                    fc_layers.append(nn.Dropout(dropout))\n",
    "                else:\n",
    "                    fc_layers.append(nn.Linear(d_model + total_cat_emb_size, hdim))\n",
    "                    fc_layers.append(nn.Dropout(dropout))\n",
    "\n",
    "            self.fc = nn.Sequential(*fc_layers)\n",
    "            self.output = nn.Linear(fc_dims[-1], 1)\n",
    "        else:\n",
    "            self.fc = None\n",
    "            self.output = nn.Linear(d_model + total_cat_emb_size, 1)\n",
    "\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        \"\"\"未来の情報を考慮しないためのマスクを生成.\n",
    "        \"\"\"\n",
    "\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = (\n",
    "            mask.float()\n",
    "            .masked_fill(mask == 0, float(\"-inf\"))\n",
    "            .masked_fill(mask == 1, float(0.0))\n",
    "        )\n",
    "        return mask\n",
    "    \n",
    "    def _reset_parameters(self):\n",
    "        \"\"\"パラメータを初期化.\n",
    "        \"\"\"\n",
    "\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                xavier_uniform_(p)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        src: Optional[Tensor] = None, \n",
    "        src_cat_idx: Optional[Tensor] = None, \n",
    "        tgt: Optional[Tensor] = None, \n",
    "        tgt_cat_idx: Optional[Tensor] = None, \n",
    "        memory: Optional[Tensor] = None\n",
    "    ) -> Tensor:\n",
    "        \"\"\"Transformerを適用.\n",
    "\n",
    "        Args:\n",
    "            src: Encoder input（数値）\n",
    "            src_cat_idx: Encoder input（カテゴリ）\n",
    "            tgt: Decoder input（数値）\n",
    "            tgt_cat_idx: Decoder input（カテゴリ）\n",
    "            memory: Encoder output\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "        if src is not None:\n",
    "            src = Variable(src, requires_grad=True).to(self.device).float()\n",
    "\n",
    "            if src_cat_idx is not None:\n",
    "                src_cat = torch.cat(\n",
    "                    [\n",
    "                        emb_layer(src_cat_idx[:, :, cat_i])\n",
    "                        for cat_i, emb_layer in enumerate(self.cat_embs)\n",
    "                    ],\n",
    "                    dim=-1,\n",
    "                )\n",
    "                src = torch.cat([src_cat.to(self.device), src], dim=-1)\n",
    "\n",
    "            src = self.pos_encoder(src)\n",
    "\n",
    "            if self.use_src_mask:\n",
    "                if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "                    mask = self._generate_square_subsequent_mask(len(src)).to(\n",
    "                        self.device\n",
    "                    )\n",
    "                    self.src_mask = mask\n",
    "\n",
    "            memory = self.transformer_encoder(src, mask=self.src_mask)\n",
    "\n",
    "        if tgt is None:\n",
    "            return memory\n",
    "        else:\n",
    "            tgt = Variable(tgt, requires_grad=True).to(self.device).float()\n",
    "\n",
    "            if tgt_cat_idx is not None:\n",
    "                tgt_cat = torch.cat(\n",
    "                    [\n",
    "                        emb_layer(tgt_cat_idx[:, :, cat_i])\n",
    "                        for cat_i, emb_layer in enumerate(self.cat_embs)\n",
    "                    ],\n",
    "                    dim=-1,\n",
    "                )\n",
    "                tgt = torch.cat([tgt_cat.to(self.device), tgt], dim=-1)\n",
    "\n",
    "            #             tgt = self.pos_encoder(tgt)\n",
    "\n",
    "            if self.tgt_mask is None or self.tgt_mask.size(0) != len(tgt):\n",
    "                mask = self._generate_square_subsequent_mask(len(tgt)).to(self.device)\n",
    "                self.tgt_mask = mask\n",
    "\n",
    "            decoder_output = self.transformer_decoder(\n",
    "                tgt, memory, tgt_mask=self.tgt_mask\n",
    "            )\n",
    "\n",
    "            fc_input = decoder_output\n",
    "\n",
    "            if self.fc is not None:\n",
    "                fc_output = self.fc(fc_input)\n",
    "            else:\n",
    "                fc_output = fc_input\n",
    "\n",
    "            output = self.output(fc_output)\n",
    "\n",
    "            return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2147bf59-335c-4e40-bc7b-a147be96c7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    '''Positional Encoding.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"PositionalEncodingを適用.\n",
    "        \"\"\"\n",
    "\n",
    "        x = x + self.pe[: x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43211eb7-50ef-4526-b60e-7f5add3fd42f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
