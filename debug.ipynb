{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fe347ef-5050-4428-afe0-977c76a96307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext import data\n",
    "from torchtext.legacy import data\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import datetime\n",
    "import shutil\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import copy\n",
    "import sys\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "942cc90c-08ed-4d8d-bc4b-c18a99e4f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle書き込み\n",
    "# ログなしVer\n",
    "def write_pickle_quickly(filepath, data):\n",
    "    with open(filepath, 'wb') as p:\n",
    "        pickle.dump(data,p)\n",
    "        \n",
    "# pickle読み出し\n",
    "# ログなしVer\n",
    "def read_pickle_quickly(filepath):\n",
    "    with open(filepath, 'rb') as p:\n",
    "        data = pickle.load(p)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed1ce0c2-1f82-4753-a006-373be1ea2906",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512   # embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b71153c-5de6-4c7c-917f-c29ee810cb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer-LSTMモデルの概要\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 d_model: int):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dense1 = nn.Linear(128,d_model)\n",
    "        self.dense2 = nn.Linear(d_model,d_model*2)\n",
    "        self.dense3 = nn.Linear(d_model*2,d_model)\n",
    "        self.dense4 = nn.Linear(d_model,3)\n",
    "        \n",
    "        self.dense5 = nn.Linear(3,16)\n",
    "        self.dense6 = nn.Linear(16,3)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.dense1.bias.data.zero_()\n",
    "        self.dense1.weight.data.uniform_(-initrange, initrange)\n",
    "        self.dense2.bias.data.zero_()\n",
    "        self.dense2.weight.data.uniform_(-initrange, initrange)\n",
    "        self.dense3.bias.data.zero_()\n",
    "        self.dense3.weight.data.uniform_(-initrange, initrange)\n",
    "        self.dense4.bias.data.zero_()\n",
    "        self.dense4.weight.data.uniform_(-initrange, initrange)\n",
    "        self.dense5.bias.data.zero_()\n",
    "        self.dense5.weight.data.uniform_(-initrange, initrange)\n",
    "        self.dense6.bias.data.zero_()\n",
    "        self.dense6.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    #データの流れ\n",
    "    def forward(self, ids):# [batch_size, 3]\n",
    "        for i in range(0,5):\n",
    "            x = self.dense1(ids) # [batch_size, d_model]\n",
    "            x = self.dense2(x) # [batch_size, d_model1*2]\n",
    "            x = self.dense3(x) # [batch_size, d_model]\n",
    "            x = self.dense4(x) # [batch_size, 3]\n",
    "            print(f'1.{x=}')\n",
    "            write_pickle_quickly(f'pickle/test_{i}.pickle', x)\n",
    "        \n",
    "        l = []\n",
    "        for i in range(0,5):\n",
    "            x = read_pickle_quickly(f'pickle/test_{i}.pickle')\n",
    "            l.append(x.unsqueeze(0))\n",
    "        \n",
    "        x = torch.cat(l, dim=0).to(torch.float).to(device)         \n",
    "        x = x.mean(dim=0)\n",
    "        x = self.dense5(x) # [batch_size, d_model]\n",
    "        x = self.dense6(x) # [batch_size, d_model1*2]\n",
    "        print(f'2.{x=}')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "393c4916-649c-4b9e-bcb3-40c4ac8ca54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4b680eefd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# paramator for training & evaluation\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "lr = 1e-3\n",
    "model = Net(d_model).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78856777-b125-4c33-a033-429dc7f61bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "def train(model):\n",
    "    model.train()\n",
    "    x = torch.randn(128)\n",
    "    \n",
    "    for i in range(0, 5):\n",
    "        predictions = model(x.to(device)).unsqueeze(0)\n",
    "        targets = torch.tensor([i%3]).to(device)\n",
    "        loss = criterion(predictions, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff92edd-cf38-4bea-b78e-0ad3ebc29604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期値\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b587a60-7979-4f17-b2cd-ec6c2dc040a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "epochs = 5\n",
    "dt_start = datetime.datetime.now()\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "print('*'*45 + 'training start' + '*'*45)\n",
    "\n",
    "# training & test roop\n",
    "for epoch in range(1, epochs + 1):\n",
    "    print('-'*100)\n",
    "    epoch_start = time.time()\n",
    "    train(model)\n",
    "    for param in model.parameters():\n",
    "        print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb931c8-4d8e-418e-917e-051174283ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''        \n",
    "        l=[]\n",
    "        for i in range(0,5):\n",
    "            x = self.dense1(ids) # [batch_size, d_model]\n",
    "            x = self.dense2(x) # [batch_size, d_model1*2]\n",
    "            x = self.dense3(x) # [batch_size, d_model]\n",
    "            x = self.dense4(x) # [batch_size, 3]\n",
    "            l.append(x.unsqueeze(0).to('cpu'))    \n",
    "        x = torch.cat(l, dim=0).to(torch.float).to(device)         \n",
    "        x = x.mean(dim=0)\n",
    "        x = self.dense5(x) # [batch_size, d_model]\n",
    "        x = self.dense6(x) # [batch_size, d_model1*2]\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
